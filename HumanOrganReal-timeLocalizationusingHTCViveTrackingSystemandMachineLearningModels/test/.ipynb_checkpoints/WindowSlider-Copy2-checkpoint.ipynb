{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "from sklearn.metrics import r2_score\n",
    "import random\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import time"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import copy as cp"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "############import data RotationX\n",
    "\n",
    "\n",
    "# dfx = pd.read_csv('data/data_tracker1_pitch.csv',sep=',')\n",
    "dfx = pd.read_csv('data/nonrigid_rollall_processed.csv',sep=',')\n",
    "\n",
    "\n",
    "dfx.columns= ['y', 'x1', 'x2', 'x3','x4','x5','x6']\n",
    "dfx=dfx[['x1','x2','x3','x4','x5','x6','y']]\n",
    "dfx.head"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "###########add timestamp\n",
    "N = 6139\n",
    "\n",
    "\n",
    "t = np.arange(0, N, 1).reshape(-1,1)\n",
    "t = np.array([t[i] + np.random.rand(1)/4 for i in range(len(t))])\n",
    "t = np.array([t[i] - np.random.rand(1)/7 for i in range(len(t))])\n",
    "t = np.array(np.round(t, 2))\n",
    "\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#############combine timestamp with RotationX dataframe\n",
    "\n",
    "\n",
    "dataset = pd.DataFrame(np.concatenate((t, dfx), axis=1), \n",
    "                       columns=['t','x1', 'x2', 'x3','x4','x5','x6','y'])\n",
    "\n",
    "deltaT = np.array([(dataset.t[i + 1] - dataset.t[i]) for i in range(len(dataset)-1)])\n",
    "deltaT = np.concatenate((np.array([0]), deltaT))\n",
    "\n",
    "dataset.insert(1, '∆t', deltaT)\n",
    "\n",
    "\n",
    "dataset.head(15)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "############split dataset into training and testing sets\n",
    "\n",
    "trainset = dataset.sample(frac=0.67, random_state=25)\n",
    "testset = dataset.drop(trainset.index)\n",
    "#trainset.head()\n",
    "trainset.shape\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "############# linear model without window technique\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import time\n",
    "\n",
    "\n",
    "gbr = GradientBoostingRegressor(random_state=0)\n",
    "\n",
    "gbr.fit(trainset.iloc[:,:-1], trainset.iloc[:,-1])\n",
    "\n",
    "t0 = time.time()\n",
    "gbr_y = testset['y'].values\n",
    "gbr_y_fit = gbr.predict(trainset.iloc[:,:-1])\n",
    "gbr_y_pred = gbr.predict(testset.iloc[:,:-1])\n",
    "tF = time.time()\n",
    "\n",
    "gbr_residuals = gbr_y_pred - gbr_y\n",
    "gbr_rmse = np.sqrt(np.sum(np.power(gbr_residuals,2)) / len(gbr_residuals))\n",
    "print('RMSE = %.2f' % gbr_rmse)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "####### WindowSlider help function\n",
    "ridge_rmse={}\n",
    "ridge_rmse_list=[]\n",
    "for m in range(100,4112,100):\n",
    "\n",
    "    class WindowSlider(object):\n",
    "        \n",
    "        def __init__(self, window_size = m):        \n",
    "            '''\n",
    "            Window Slider object\n",
    "            ====================\n",
    "            w: window_size - number of time steps to look back\n",
    "            o: offset between last reading and temperature\n",
    "            r: response_size - number of time steps to predict\n",
    "            l: maximum length to slide - (#observation - w)\n",
    "            p: final predictors - (#predictors * w)\n",
    "            '''\n",
    "            self.w = window_size\n",
    "            self.o = 0\n",
    "            self.r = 1       \n",
    "            self.l = 0\n",
    "            self.p = 0\n",
    "            self.names = []\n",
    "        \n",
    "        def re_init(self, arr):\n",
    "            '''\n",
    "            Helper function to initializate to 0 a vector\n",
    "            '''\n",
    "            arr = np.cumsum(arr)\n",
    "            return arr - arr[0]\n",
    "                \n",
    "\n",
    "        def collect_windows(self, X, window_size=m, offset=0, previous_y=False):\n",
    "            '''\n",
    "            Input: X is the input matrix, each column is a variable\n",
    "            Returns: diferent mappings window-output\n",
    "            '''\n",
    "            cols = len(list(X)) - 1\n",
    "            N = len(X)\n",
    "        \n",
    "            self.o = offset\n",
    "            self.w = window_size\n",
    "            self.l = N - (self.w + self.r) + 1\n",
    "            if not previous_y: self.p = cols * (self.w)\n",
    "            if previous_y: self.p = (cols + 1) * (self.w)\n",
    "        \n",
    "            # Create the names of the variables in the window\n",
    "            # Check first if we need to create that for the response itself\n",
    "            if previous_y: x = cp.deepcopy(X)\n",
    "            if not previous_y: x = X.drop(X.columns[-1], axis=1)  \n",
    "        \n",
    "            for j, col in enumerate(list(x)):        \n",
    "                \n",
    "                for i in range(self.w):\n",
    "                \n",
    "                    name = col + ('(%d)' % (i+1))\n",
    "                    self.names.append(name)\n",
    "        \n",
    "            # Incorporate the timestamps where we want to predict\n",
    "            for k in range(self.r):\n",
    "            \n",
    "                name = '∆t' + ('(%d)' % (self.w + k + 1))\n",
    "                self.names.append(name)\n",
    "            \n",
    "            self.names.append('Y')\n",
    "                \n",
    "            df = pd.DataFrame(np.zeros(shape=(self.l, (self.p + self.r + 1))), \n",
    "                          columns=self.names)\n",
    "        \n",
    "            # Populate by rows in the new dataframe\n",
    "            for i in range(self.l):\n",
    "            \n",
    "                slices = np.array([])\n",
    "            \n",
    "                # Flatten the lags of predictors\n",
    "                for p in range(x.shape[1]):\n",
    "            \n",
    "                    line = X.values[i:self.w + i, p]\n",
    "                    # Reinitialization at every window for ∆T\n",
    "                    if p == 0: line = self.re_init(line)\n",
    "                    \n",
    "                    # Concatenate the lines in one slice    \n",
    "                    slices = np.concatenate((slices, line)) \n",
    " \n",
    "                # Incorporate the timestamps where we want to predict\n",
    "    \n",
    "                line = np.array([self.re_init(X.values[i:i+self.w+self.r, 0])[-1]])\n",
    "                y = np.array(X.values[self.w + i + self.r - 1, -1]).reshape(1,)\n",
    "                slices = np.concatenate((slices, line, y))\n",
    "            \n",
    "                # Incorporate the slice to the cake (df)\n",
    "                df.iloc[i,:] = slices\n",
    "            \n",
    "            return df\n",
    "        \n",
    " \n",
    "    w=m\n",
    "    train_constructor = WindowSlider()\n",
    "    train_windows = train_constructor.collect_windows(trainset.iloc[:,1:], \n",
    "                                                  previous_y=False)\n",
    "\n",
    "    test_constructor = WindowSlider()\n",
    "    test_windows = test_constructor.collect_windows(dataset.iloc[4113-w:,1:],\n",
    "                                                previous_y=False)\n",
    "\n",
    "    train_constructor_y_inc = WindowSlider()\n",
    "    train_windows_y_inc = train_constructor_y_inc.collect_windows(trainset.iloc[:,1:], \n",
    "                                                  previous_y=True)\n",
    "\n",
    "    test_constructor_y_inc = WindowSlider()\n",
    "    test_windows_y_inc = test_constructor_y_inc.collect_windows(dataset.iloc[4113-w:,1:],\n",
    "                                                previous_y=True)\n",
    "\n",
    "    #train_windows.head(3)\n",
    "    #test_windows.head(3)\n",
    "    \n",
    "    ridge_model = Ridge()\n",
    "    ridge_model.fit(train_windows.iloc[:,:-1], train_windows.iloc[:,-1])\n",
    "\n",
    "\n",
    "\n",
    "    t0 = time.time()\n",
    "    ridge_y = test_windows['Y'].values\n",
    "    ridge_y_fit = ridge_model.predict(train_windows.iloc[:,:-1])\n",
    "    ridge_y_pred = ridge_model.predict(test_windows.iloc[:,:-1])\n",
    "    tF = time.time()\n",
    "\n",
    "    ridge_residuals = ridge_y_pred - ridge_y\n",
    "    ridge_rmse[m] = np.sqrt(np.sum(np.power(ridge_residuals,2)) / len(ridge_residuals))\n",
    "    ridge_rmse_list.append(ridge_rmse[m])\n",
    "    \n",
    "print(ridge_rmse_list)       "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "x_ridge=range(100,4112,100)\n",
    "\n",
    "y_ridge=ridge_rmse_list\n",
    "\n",
    "plt.plot(x_ridge, y_ridge, label = \"Ridge Regression\")\n",
    "\n",
    "  \n",
    "# naming the x axis\n",
    "plt.xlabel('Window Size')\n",
    "# naming the y axis\n",
    "plt.ylabel('RMSE')\n",
    "\n",
    "  \n",
    "# function to show the plot\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#######GBR\n",
    "\n",
    "####### WindowSlider help function\n",
    "gbr_rmse={}\n",
    "gbr_rmse_list=[]\n",
    "for m in range(100,4112,100):\n",
    "\n",
    "    class WindowSlider(object):\n",
    "        \n",
    "        def __init__(self, window_size = m):        \n",
    "            '''\n",
    "            Window Slider object\n",
    "            ====================\n",
    "            w: window_size - number of time steps to look back\n",
    "            o: offset between last reading and temperature\n",
    "            r: response_size - number of time steps to predict\n",
    "            l: maximum length to slide - (#observation - w)\n",
    "            p: final predictors - (#predictors * w)\n",
    "            '''\n",
    "            self.w = window_size\n",
    "            self.o = 0\n",
    "            self.r = 1       \n",
    "            self.l = 0\n",
    "            self.p = 0\n",
    "            self.names = []\n",
    "        \n",
    "        def re_init(self, arr):\n",
    "            '''\n",
    "            Helper function to initializate to 0 a vector\n",
    "            '''\n",
    "            arr = np.cumsum(arr)\n",
    "            return arr - arr[0]\n",
    "                \n",
    "\n",
    "        def collect_windows(self, X, window_size=m, offset=0, previous_y=False):\n",
    "            '''\n",
    "            Input: X is the input matrix, each column is a variable\n",
    "            Returns: diferent mappings window-output\n",
    "            '''\n",
    "            cols = len(list(X)) - 1\n",
    "            N = len(X)\n",
    "        \n",
    "            self.o = offset\n",
    "            self.w = window_size\n",
    "            self.l = N - (self.w + self.r) + 1\n",
    "            if not previous_y: self.p = cols * (self.w)\n",
    "            if previous_y: self.p = (cols + 1) * (self.w)\n",
    "        \n",
    "            # Create the names of the variables in the window\n",
    "            # Check first if we need to create that for the response itself\n",
    "            if previous_y: x = cp.deepcopy(X)\n",
    "            if not previous_y: x = X.drop(X.columns[-1], axis=1)  \n",
    "        \n",
    "            for j, col in enumerate(list(x)):        \n",
    "                \n",
    "                for i in range(self.w):\n",
    "                \n",
    "                    name = col + ('(%d)' % (i+1))\n",
    "                    self.names.append(name)\n",
    "        \n",
    "            # Incorporate the timestamps where we want to predict\n",
    "            for k in range(self.r):\n",
    "            \n",
    "                name = '∆t' + ('(%d)' % (self.w + k + 1))\n",
    "                self.names.append(name)\n",
    "            \n",
    "            self.names.append('Y')\n",
    "                \n",
    "            df = pd.DataFrame(np.zeros(shape=(self.l, (self.p + self.r + 1))), \n",
    "                          columns=self.names)\n",
    "        \n",
    "            # Populate by rows in the new dataframe\n",
    "            for i in range(self.l):\n",
    "            \n",
    "                slices = np.array([])\n",
    "            \n",
    "                # Flatten the lags of predictors\n",
    "                for p in range(x.shape[1]):\n",
    "            \n",
    "                    line = X.values[i:self.w + i, p]\n",
    "                    # Reinitialization at every window for ∆T\n",
    "                    if p == 0: line = self.re_init(line)\n",
    "                    \n",
    "                    # Concatenate the lines in one slice    \n",
    "                    slices = np.concatenate((slices, line)) \n",
    " \n",
    "                # Incorporate the timestamps where we want to predict\n",
    "    \n",
    "                line = np.array([self.re_init(X.values[i:i+self.w+self.r, 0])[-1]])\n",
    "                y = np.array(X.values[self.w + i + self.r - 1, -1]).reshape(1,)\n",
    "                slices = np.concatenate((slices, line, y))\n",
    "            \n",
    "                # Incorporate the slice to the cake (df)\n",
    "                df.iloc[i,:] = slices\n",
    "            \n",
    "            return df\n",
    "        \n",
    " \n",
    "    w=m\n",
    "    train_constructor = WindowSlider()\n",
    "    train_windows = train_constructor.collect_windows(trainset.iloc[:,1:], \n",
    "                                                  previous_y=False)\n",
    "\n",
    "    test_constructor = WindowSlider()\n",
    "    test_windows = test_constructor.collect_windows(dataset.iloc[4113-w:,1:],\n",
    "                                                previous_y=False)\n",
    "\n",
    "    train_constructor_y_inc = WindowSlider()\n",
    "    train_windows_y_inc = train_constructor_y_inc.collect_windows(trainset.iloc[:,1:], \n",
    "                                                  previous_y=True)\n",
    "\n",
    "    test_constructor_y_inc = WindowSlider()\n",
    "    test_windows_y_inc = test_constructor_y_inc.collect_windows(dataset.iloc[4113-w:,1:],\n",
    "                                                previous_y=True)\n",
    "\n",
    "    #train_windows.head(3)\n",
    "    #test_windows.head(3)\n",
    "    \n",
    "    gbr_model = GradientBoostingRegressor()\n",
    "    gbr_model.fit(train_windows.iloc[:,:-1], train_windows.iloc[:,-1])\n",
    "\n",
    "\n",
    "\n",
    "    t0 = time.time()\n",
    "    gbr_y = test_windows['Y'].values\n",
    "    gbr_y_fit = gbr_model.predict(train_windows.iloc[:,:-1])\n",
    "    gbr_y_pred = gbr_model.predict(test_windows.iloc[:,:-1])\n",
    "    tF = time.time()\n",
    "\n",
    "    gbr_residuals = gbr_y_pred - gbr_y\n",
    "    gbr_rmse[m] = np.sqrt(np.sum(np.power(gbr_residuals,2)) / len(gbr_residuals))\n",
    "    gbr_rmse_list.append(gbr_rmse[m])\n",
    "    \n",
    "print(gbr_rmse_list)  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x_gbr=range(100,4112,100)\n",
    "\n",
    "y_gbr=gbr_rmse_list\n",
    "\n",
    "plt.plot(x_gbr, y_gbr, label = \"Gradient Boosting Regressor\")\n",
    "\n",
    "  \n",
    "# naming the x axis\n",
    "plt.xlabel('Window Size')\n",
    "# naming the y axis\n",
    "plt.ylabel('RMSE')\n",
    "\n",
    "  \n",
    "# function to show the plot\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pip install statsmodels "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "######autocorrelation \n",
    "\n",
    "from statsmodels.graphics import tsaplots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "x=dfx[[\"y\"]]\n",
    "#plot autocorrelation function\n",
    "fig = tsaplots.plot_acf(x, lags=4000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "################# GBR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gbr = GradientBoostingRegressor(random_state=0)\n",
    "\n",
    "gbr.fit(train_windows.iloc[:,:-1], train_windows.iloc[:,-1])\n",
    "\n",
    "t0 = time.time()\n",
    "gbr_y = test_windows['Y'].values\n",
    "gbr_y_fit = gbr.predict(train_windows.iloc[:,:-1])\n",
    "gbr_y_pred = gbr.predict(test_windows.iloc[:,:-1])\n",
    "tF = time.time()\n",
    "\n",
    "gbr_residuals = gbr_y_pred - gbr_y\n",
    "gbr_rmse = np.sqrt(np.sum(np.power(gbr_residuals,2)) / len(gbr_residuals))\n",
    "print('RMSE = %.2f' % gbr_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
